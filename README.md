# Exploring Musical Emotion Visualization Through Acoustic Feature Mapping

## Abstract
This project explores whether the emotional qualities of music can be communicated visually by mapping the set of acustic features, Energy (RMS), Spectral Centroid and Tempo (BPM), to simple dynamic visual parameters such as movement intensity, color and rhythmic pulsing. This is explored using four short instrumental excerpts, each of which conveys an emotion (happiness, sadness, fear, calm). The system perform feature extraction and generates visuals whose temporal evolution is related with the set of acustic features. A user study compares valence and arousal ratings accross three different tests, audio only, visual only, and audio+visual, with the goal to evaluate how these visuals approximate or modify the emotional impressions of the music. By examining how visual changes generated from acoustic features evoke emotional responses, the project aims to explore, on a small scale, how musical emotion can be experienced through sight, with potential implications for users with hearing impairments.

---
## Introduction
Music is widely recognized as a powerful medium capable of conveying emotions. Although the emotions generated by music are mainly transmitted through sound, people often describe the experience using visual imagery such as colors, shapes, movements or atmospheres inspired by the music (Dahl et al., 2023). This observation suggests the existence of significant relationships between acoustic structure and visual representation, opening the possibility to investigate how music can be experienced through visual channels.
(unfinished)

---
## Theoretical Framework and Related Studies
- Musical emotion and the valence-arousal model (Russell, 1980)
- Acoustic features and their role in emotional perception (Haumann, 2018, 2021): Describe relationships between acoustic features and emotion and justify my selection of three features.
- Music evoked mental imagery (Dahl, 2023): Sometimes listeners saw mental visual imagery when hearing music. Imagery patterns often correspond to acoustic properties.
- Relationships between sound and vision (Spence 2011, Palmer 2013, Marks 1975, Tresilian 2020): justification of why visuals can evoke similar emotions, how humans match diferent acustic features to visual changes. Justification of my visual features choice and their mapping to an acustic feature.
- Short paragraph summarizing and leading into the Research Question and Hypotheses.

---
## Research Question & Hypotheses
Can visuals generated from Energy (RMS), Spectral Centroid and Tempo (BPM) evoke emotional impressions similar to those experienced during music listening through changes in movement, color and rhythmic pulsing?

H1: When the acoustic features of the music are translated into visual changes, those visuals on their own should evoke predictable emotional responses. (Independet variables: Acustic features) (Dependent variables: valence and arousal in the visual test)
H2: It is expected that the emotional responses elicited by the visual only test will fall within the same quadrant (or similar) of the valence-arousal space as the responses elicited by the audio only test. (Independent variable: Test modality) (Dependent variables: valence and arousal)
H3: When audio and visuals are presented together, it is expected to produce enhanced emotional responses than with each individual condition. (Independent variable: Test modality) (Dependent variables: valence and arousal)

---
## Methodology

---
## Expected Outcomes

---
### References

---

*Authored by Joan Mont√©s Mora - MSc in Medialogy | Sound & Music Perception and Cognition course 2025*
